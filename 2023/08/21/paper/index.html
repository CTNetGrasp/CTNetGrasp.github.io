<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover" name="viewport" />
    <link rel="alternate icon" type="image/png" href="/xiejialong.github.io/CTNet/img/favicon.png">
    <title>paper | </title>
    
<link rel="stylesheet" href="/xiejialong.github.io/CTNet/css/reset.css">

    
<link rel="stylesheet" href="/xiejialong.github.io/CTNet/css/style.css">

    
<link rel="stylesheet" href="/xiejialong.github.io/CTNet/css/markdown.css">

    
<link rel="stylesheet" href="/xiejialong.github.io/CTNet/css/fonts.css">


    <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css">
<meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <div class="paper">
            <div class="paper-main">

                <div class="post-main">

    
    
        <div class="post-main-title">
            Listen, Perceive, Grasp : CLIP-driven attribute-aware network for visual-language segmentation and grasping detection
        </div>
        <div class="post-meta">
            2023-08-21
        </div>
        <div class="post-md">
            <h3 id="The-listen-perceive-grasp-paradigm-for-robotic-grasp-reasoning"><a href="#The-listen-perceive-grasp-paradigm-for-robotic-grasp-reasoning" class="headerlink" title="The listen-perceive-grasp paradigm for robotic grasp reasoning"></a>The <em>listen-perceive-grasp</em> paradigm for robotic grasp reasoning</h3><p><img src="/xiejialong.github.io/CTNet/./images/Schematic.jpg" alt="listen-perceive-grasp paradigm"><br><br /></p>
<h3 id="Overview-of-CTNet"><a href="#Overview-of-CTNet" class="headerlink" title="Overview of CTNet"></a>Overview of CTNet</h3><p><img src="/xiejialong.github.io/CTNet/./images/architecture.jpg" alt="listen-perceive-grasp paradigm"><br><img src="/xiejialong.github.io/CTNet/./images/TAMMI.jpg" alt="TAMMI"></p>
<br />

<h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><p><img src="/xiejialong.github.io/CTNet/./images/visualization.jpg" alt="Visualization"></p>
<!-- ### Real-world robotic grasping experiments
<iframe src="//www.youtube.com/embed/IfjVsa1t2Jw" frameborder="0" allowfullscreen="" width='640' height='480'></iframe> -->
        </div>

    

</div>
                <div class="footer">
    <span>Copyright © 2022 paper</span>
    <span>Theme Designed By <a target="_blank" href="https://zheli.design/one-paper">這李設計</a></span>
</div>


<link rel="stylesheet" href="/xiejialong.github.io/CTNet/css/a11y-dark.min.css">


<script src="/xiejialong.github.io/CTNet/js/highlight.min.js"></script>


<script src="/xiejialong.github.io/CTNet/js/highlightjs-line-numbers.js"></script>


<script>
    hljs.initHighlightingOnLoad();
    hljs.initLineNumbersOnLoad();
</script>

            </div>
        </div>
    </body>
</html>